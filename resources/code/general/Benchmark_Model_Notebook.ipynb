{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d672a-a1ff-4806-9dce-5f8c9a4f051b",
   "metadata": {},
   "source": [
    "# Water Quality Prediction: Benchmark Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e8dca-8e21-478c-b9d8-8162214025ef",
   "metadata": {},
   "source": [
    "## Challenge Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38782b-973e-4f63-83b3-3e556abae629",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "Welcome to the EY AI & Data Challenge 2026!  \n",
    "The objective of this challenge is to build a robust <strong> machine learning model </strong>capable of predicting water quality across various river locations in South Africa. In addition to accurate predictions, the model should also identify and emphasize the key factors that significantly influence water quality.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "Participants will be provided with a dataset containing three water quality parameters <strong>Total Alkalinity</strong>, <strong>Electrical Conductance</strong>, and <strong>Dissolved Reactive Phosphorus</strong> collected between 2011 and 2015 from approximately 200 river locations across South Africa. Each data point includes the geographic coordinates (latitude and longitude) of the sampling site, the date of collection, and the corresponding water quality measurements.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "Using this dataset, participants are expected to build a machine learning model to predict water quality parameters for a separate validation dataset, which includes locations from different regions not present in the training data. The challenge also encourages participants to explore feature importance and provide insights into the factors most strongly associated with variations in water quality.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "This challenge is designed for participants with varying levels of experience in data science, remote sensing, and environmental analytics. It offers a valuable opportunity to apply machine learning techniques to real-world environmental data and contribute to advancing water quality monitoring using artificial intelligence.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5ca99-0ab8-4117-8bf1-991714e656be",
   "metadata": {},
   "source": [
    "<b>About the Notebook: </b><p align=\"justify\"> <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be35cd-7ec3-4697-b476-efb378803e53",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> In this notebook, we demonstrate a basic workflow that serves as a foundation for the challenge. The model has been developed to predict <b>water quality parameters</b> using features derived from the <b>Landsat</b> and <b>TerraClimate</b> datasets. Specifically, four spectral bands—<b>SWIR22</b> (Shortwave Infrared 2), <b>NIR</b> (Near Infrared), <b>Green</b>, and <b>SWIR16</b> (Shortwave Infrared 1)—were utilized from Landsat, along with derived spectral indices such as <b>NDMI</b> (Normalized Difference Moisture Index) and <b>MNDWI</b> (Modified Normalized Difference Water Index). In addition, the <b>PET</b> (Potential Evapotranspiration) variable was incorporated from the <b>TerraClimate</b> dataset to account for climatic influences on water quality. </p> \n",
    "\n",
    "<p align=\"justify\"> The dataset spans a five-year period from <b>2011 to 2015</b>. Using <b>API-based data extraction</b> methods, both Landsat and TerraClimate features were retrieved directly from the <a href=\"https://planetarycomputer.microsoft.com/\">Microsoft Planetary Computer</a> portal. These combined spectral, index-based, and climatic features were used as predictors in a regression model to estimate three key water quality parameters: <b>Total Alkalinity (TA)</b>, <b>Electrical Conductance (EC)</b>, and <b>Dissolved Reactive Phosphorus (DRP)</b>. \n",
    "\n",
    "</p> <p align=\"justify\"> Please note that this notebook serves only as a starting point. Several assumptions were made during the data extraction and model development process, which you may find opportunities to improve upon. Participants are encouraged to explore additional features, enhance preprocessing techniques, or experiment with different regression algorithms to optimize predictive performance. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57447c9d-ceca-4a26-8066-2dca61e0e224",
   "metadata": {},
   "source": [
    "## Load In Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fef275-cf07-45bf-9b38-2b876e5b111f",
   "metadata": {},
   "source": [
    "To run this demonstration notebook, you will need to have the following packages imported below installed. This may take some time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53ef74f-52ba-4c63-b412-2f4432408d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\n",
    "import xarray as xr\n",
    "\n",
    "# Geospatial raster data handling with CRS support\n",
    "import rioxarray as rxr\n",
    "\n",
    "# Raster operations and spatial windowing\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# Feature preprocessing and data splitting\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Planetary Computer tools for STAC API access and authentication\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from odc.stac import stac_load\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcbb20-8dff-401a-9f55-ed5d08eb6b60",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e1bce-f161-4d24-9f6b-a60778c39585",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "Before building the model, we first load the <b>water quality training dataset</b>. The curated dataset contains samples collected from various monitoring stations across the study region. Each record includes the geographical coordinates (Latitude and Longitude), the sample collection date, and the corresponding <b>measured values</b> for the three key water quality parameters — <b>Total Alkalinity (TA)</b>, <b>Electrical Conductance (EC)</b>, and <b>Dissolved Reactive Phosphorus (DRP)</b>.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78281644-14cb-4923-aa67-188808db80ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  02-01-2011           128.912                   555.0   \n",
       "1 -26.861111  28.884722  03-01-2011            74.720                   162.9   \n",
       "2 -26.450000  28.085833  03-01-2011            89.254                   573.0   \n",
       "3 -27.671111  27.236944  03-01-2011            82.000                   203.6   \n",
       "4 -27.356667  27.286389  03-01-2011            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                           10.0  \n",
       "1                          163.0  \n",
       "2                           80.0  \n",
       "3                          101.0  \n",
       "4                          151.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Water_Quality_df=pd.read_csv('water_quality_training_dataset.csv')\n",
    "Water_Quality_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac87b43-019d-4aa4-bb4b-62b40cc6cda2",
   "metadata": {},
   "source": [
    "## Predictor Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bbd80-887c-4c1f-83f4-3d31ffc40551",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "Now that we have our water quality dataset, the next step is to gather the predictor variables from the <b>Landsat</b> and <b>TerraClimate</b> datasets. In this notebook, we demonstrate how to <b>load previously extracted satellite and climate data</b> from separate files, rather than performing the extraction directly, which allows for a smoother and faster experience. Participants can refer to the dedicated extraction notebooks—one for Landsat and another for TerraClimate—to understand how the data was retrieved and processed, and they can also generate their own output CSV files if needed. Using these pre-extracted CSV files, this notebook focuses on loading the predictor features and running the subsequent analysis and model training efficiently.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "For more detailed guidance on the original data extraction process, you can review the <a href=\"https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2#Example-Notebook\">Landsat example notebook</a> and the <a href=\"https://planetarycomputer.microsoft.com/dataset/terraclimate#Example-Notebook\">TerraClimate example notebook</a> available on the Planetary Computer portal.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">We have used selected spectral bands — SWIR22 (Shortwave Infrared 2), NIR (Near Infrared), Green, and SWIR16 (Shortwave Infrared 1) — and computed key spectral indices such as NDMI (Normalized Difference Moisture Index) and MNDWI (Modified Normalized Difference Water Index). These features capture surface moisture, vegetation, and water content characteristics that influence water quality variability. </p> <p align=\"justify\"> In addition to Landsat features, we also incorporated the <b>Potential Evapotranspiration (PET)</b> variable from the <b>TerraClimate</b> dataset, which provides high-resolution global climate data. The PET feature captures the atmospheric demand for moisture, representing climatic conditions such as temperature, humidity, and radiation that influence surface water evaporation and thus affect water quality parameters. </p> <ul> <li>SWIR22 – Sensitive to surface moisture and turbidity variations in water bodies.</li> <li>NIR – Helps in identifying vegetation and suspended matter in water.</li> <li>Green – Useful for detecting water color and surface reflectance changes.</li> <li>SWIR16 – Provides information on surface dryness and sediment concentration.</li> <li>NDMI – Derived from NIR and SWIR16, indicates moisture and vegetation-water interaction.</li> <li>MNDWI – Derived from Green and SWIR22, effective for distinguishing open water areas and reducing built-up noise.</li> <li>PET – Extracted from the TerraClimate dataset, represents the potential evapotranspiration that influences hydrological and water quality dynamics.</li> </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced81f1-3b77-4a69-ac48-9d02cc12c647",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(255, 0, 0)\"><strong>Tip 1</strong></h4>  \n",
    "<p align=\"justify\">  \n",
    "Participants are encouraged to experiment with different combinations of <b>Landsat</b> bands or even include data from other public satellite data sources. By creating mathematical combinations of bands, you can derive various spectral indices that capture surface and environmental characteristics. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0c7e8-9471-4a09-9ac4-6a5b5f0703bd",
   "metadata": {},
   "source": [
    "<h3>Loading Pre-Extracted Landsat Data</h3>\n",
    "<p align=\"justify\">\n",
    "In this notebook, we <b>load previously extracted Landsat data</b> from CSV files generated in a separate extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "Participants are expected to generate their own data extraction CSV files by running the dedicated Landsat extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how individual bands and indices like <b>NDMI</b> were computed. Using these pre-extracted CSV files simplifies preprocessing and is ideal for large-scale environmental and water quality analysis.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe34327-f165-452c-98ef-3df67b6ed550",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(255, 0, 0)\"><strong>Tip 2</strong></h4>\n",
    "In the data extraction process (performed in the dedicated extraction notebooks), a 100 m focal buffer was applied around each sampling location rather than using a single point. Participants may explore creating different focal buffers around the locations (e.g., 50 m, 150 m, etc.) during extraction. For example, if a 50 m buffer was used for “Band 2”, the extracted CSV values would reflect the average of \"Band 2\" within 50 meters of each location. This approach can help reduce errors associated with spatial autocorrelation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2088358c-8963-4078-9b39-f85bdc0697ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date      nir    green   swir16   swir22  \\\n",
       "0 -28.760833  17.730278  02-01-2011  11190.0  11426.0   7687.5   7645.0   \n",
       "1 -26.861111  28.884722  03-01-2011  17658.5   9550.0  13746.5  10574.0   \n",
       "2 -26.450000  28.085833  03-01-2011  15210.0  10720.0  17974.0  14201.0   \n",
       "3 -27.671111  27.236944  03-01-2011  14887.0  10943.0  13522.0  11403.0   \n",
       "4 -27.356667  27.286389  03-01-2011  16828.5   9502.5  12665.5   9643.0   \n",
       "\n",
       "       NDMI     MNDWI  \n",
       "0  0.185538  0.195595  \n",
       "1  0.124566 -0.180134  \n",
       "2 -0.083293 -0.252805  \n",
       "3  0.048048 -0.105416  \n",
       "4  0.141147 -0.142683  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat_train_features = pd.read_csv('landsat_features_training.csv')\n",
    "landsat_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0ed5d-32c0-48f9-863c-ef84bad110d2",
   "metadata": {},
   "source": [
    "<h3>Loading Pre-Extracted TerraClimate Data</h3>\n",
    "<p align=\"justify\">\n",
    "In this notebook, we <b>load previously extracted TerraClimate data</b> from CSV files generated in a dedicated extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "Participants are expected to generate their own data extraction CSV files by running the dedicated TerraClimate extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how climate variables such as <b>Potential Evapotranspiration (PET)</b> were extracted. Using these pre-extracted CSV files ensures consistent, automated retrieval of high-resolution climate data that can be easily integrated with satellite-derived features for comprehensive environmental and hydrological analysis.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4f27bf-96e0-47b3-b217-c4532ebce51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>174.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>124.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>129.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>129.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date    pet\n",
       "0 -28.760833  17.730278  02-01-2011  174.2\n",
       "1 -26.861111  28.884722  03-01-2011  124.1\n",
       "2 -26.450000  28.085833  03-01-2011  127.5\n",
       "3 -27.671111  27.236944  03-01-2011  129.7\n",
       "4 -27.356667  27.286389  03-01-2011  129.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Terraclimate_df = pd.read_csv('terraclimate_features_training.csv')\n",
    "Terraclimate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475de826-a08c-4ea1-bbfc-5e9a3240ab22",
   "metadata": {},
   "source": [
    "## Joining the predictor variables and response variables\n",
    "Now that we have extracted our predictor variables, we need to join them onto the response variable . We use the function <i><b>combine_two_datasets</b></i> to combine the predictor variables and response variables.The <i><b>concat</b></i> function from pandas comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b42801e-e7b9-4b17-b4e4-f65fd971decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two datasets vertically (along columns) using pandas concat function.\n",
    "def combine_two_datasets(dataset1,dataset2,dataset3):\n",
    "    '''\n",
    "    Returns a  vertically concatenated dataset.\n",
    "    Attributes:\n",
    "    dataset1 - Dataset 1 to be combined \n",
    "    dataset2 - Dataset 2 to be combined\n",
    "    '''\n",
    "    \n",
    "    data = pd.concat([dataset1,dataset2,dataset3], axis=1)\n",
    "    data = data.loc[:, ~data.columns.duplicated()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c75dffde-a8e3-4a6e-bbab-bf0d8aac7bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11190.0</td>\n",
       "      <td>11426.0</td>\n",
       "      <td>7687.5</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>0.185538</td>\n",
       "      <td>0.195595</td>\n",
       "      <td>174.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "      <td>17658.5</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>13746.5</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>-0.180134</td>\n",
       "      <td>124.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>15210.0</td>\n",
       "      <td>10720.0</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>14201.0</td>\n",
       "      <td>-0.083293</td>\n",
       "      <td>-0.252805</td>\n",
       "      <td>127.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>10943.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>11403.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>-0.105416</td>\n",
       "      <td>129.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "      <td>16828.5</td>\n",
       "      <td>9502.5</td>\n",
       "      <td>12665.5</td>\n",
       "      <td>9643.0</td>\n",
       "      <td>0.141147</td>\n",
       "      <td>-0.142683</td>\n",
       "      <td>129.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  02-01-2011           128.912                   555.0   \n",
       "1 -26.861111  28.884722  03-01-2011            74.720                   162.9   \n",
       "2 -26.450000  28.085833  03-01-2011            89.254                   573.0   \n",
       "3 -27.671111  27.236944  03-01-2011            82.000                   203.6   \n",
       "4 -27.356667  27.286389  03-01-2011            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus      nir    green   swir16   swir22  \\\n",
       "0                           10.0  11190.0  11426.0   7687.5   7645.0   \n",
       "1                          163.0  17658.5   9550.0  13746.5  10574.0   \n",
       "2                           80.0  15210.0  10720.0  17974.0  14201.0   \n",
       "3                          101.0  14887.0  10943.0  13522.0  11403.0   \n",
       "4                          151.0  16828.5   9502.5  12665.5   9643.0   \n",
       "\n",
       "       NDMI     MNDWI    pet  \n",
       "0  0.185538  0.195595  174.2  \n",
       "1  0.124566 -0.180134  124.1  \n",
       "2 -0.083293 -0.252805  127.5  \n",
       "3  0.048048 -0.105416  129.7  \n",
       "4  0.141147 -0.142683  129.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining ground data and final data into a single dataset.\n",
    "wq_data = combine_two_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)\n",
    "wq_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4573656-100c-49e7-b3bb-536e0a6290ac",
   "metadata": {},
   "source": [
    "<h3>Handling Missing Values</h3>  \n",
    "<p align=\"justify\">  \n",
    "Before model training, missing values in the dataset were carefully handled to ensure data consistency and prevent model bias. Numerical columns were imputed using their median values, maintaining the overall data distribution while minimizing the impact of outliers.  \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7372e4-26c6-4bd8-9d7a-39bc35b01a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude                         0\n",
       "Longitude                        0\n",
       "Sample Date                      0\n",
       "Total Alkalinity                 0\n",
       "Electrical Conductance           0\n",
       "Dissolved Reactive Phosphorus    0\n",
       "nir                              0\n",
       "green                            0\n",
       "swir16                           0\n",
       "swir22                           0\n",
       "NDMI                             0\n",
       "MNDWI                            0\n",
       "pet                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wq_data = wq_data.fillna(wq_data.median(numeric_only=True))\n",
    "wq_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a997d-ec88-4ae0-b540-44cd3e5f6cf2",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f7c65-b3a1-405b-b912-cef4e5157bce",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> Now let us select the columns required for our model building exercise. We will consider only Band swir22, NDMI and MNDWI from the Landsat data and pet from Terraclimate dataset as our predictor variables. It does not make sense to use latitude and longitude as predictor variables, as they do not have any direct impact on predicting the water quality parameters.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35381365-adf1-4702-a99d-5cec95812ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retaining only the columns for swir22, NDMI, MNDWI, pet, Total Alkalinity, Electrical Conductance and Dissolved Reactive Phosphorus Index in the dataset.\n",
    "wq_data = wq_data[['swir22','NDMI','MNDWI','pet', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97148a55",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(255, 0, 0)\"><strong>Tip 3</strong></h4>\n",
    "<p align=\"justify\">We are developing individual models for each water quality parameter using a common set of features: SWIR22, NDMI, MNDWI, and PET. However, participants are encouraged to experiment with different feature combinations to build more robust machine learning models.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e241de9-35e2-4fa6-9bba-2d5456af838a",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "### Train and Test Split \n",
    "<p align=\"justify\">We will now split the data into 70% training data and 30% test data. Scikit-learn alias “sklearn” is a robust library for machine learning in Python. The scikit-learn library has a <i><b>model_selection</b></i> module in which there is a splitting function <i><b>train_test_split</b></i>. You can use the same.</p>\n",
    "\n",
    "### Feature Scaling \n",
    "\n",
    "<p align=\"justify\"> Before initiating the model training we may have to execute different data pre-processing steps. Here we are demonstrating the scaling of 'swir22','NDMI','MNDWI','pet' variable by using Standard Scaler.</p>\n",
    "\n",
    "<p align = \"justify\">Feature Scaling is a data preprocessing step for numerical features. Many machine learning algorithms like Gradient descent methods, KNN algorithm, linear and logistic regression, etc. require data scaling to produce good results. Scikit learn provides functions that can be used to apply data scaling. Here we are using Standard Scaler. The idea behind Standard Scaler is that it will transform your data such that its distribution will have a mean value 0 and standard deviation of 1.</p>\n",
    "\n",
    "### Model Training\n",
    "<p align=\"justify\">\n",
    "Now that we have the data in a format suitable for machine learning, we can begin training our models. In this demonstration notebook, we will build three separate regression models — one for each target water quality parameter: Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. \n",
    "Each model will be trained independently to capture the unique relationships between the satellite-derived features and each parameter.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "We will use the Random Forest Regressor from the scikit-learn library to build our models. Scikit-learn provides a wide range of regression algorithms with extensive parameter tuning and customization capabilities.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "For model training, the predictor variables (e.g., SWIR22, NDMI, MNDWI, and pet) will be stored in an array X, and the response variable (one of the three water quality parameters) will be stored in an array Y. \n",
    "It is important not to include the response variable in X. Additionally, since latitude, longitude, and sample date are only used for spatial and temporal reference, they will be excluded from the predictor variables during model training.\n",
    "</p>\n",
    "\n",
    "### Model Evaluation\n",
    "<p align=\"justify\">\n",
    "Now that we have trained our models for the three water quality parameters, the next step is to evaluate their performance. Each regression model for Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus is assessed using the R² score and the Root Mean Square Error (RMSE). The R² score measures how well the model explains the variance in the observed values, while RMSE quantifies the average magnitude of prediction errors. Together, these metrics help determine how effectively each model captures variations in water quality across different locations and sampling dates. Scikit-learn provides built-in functions to compute these metrics, and participants may explore additional evaluation methods or custom metrics as needed.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e06d5-10a6-419a-b096-52c6f0566e1f",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(255, 0, 0)\"><strong>Tip 4</strong></h4>\n",
    "<p align=\"justify\">There are many data preprocessing methods available, which might help to improve the model performance. Participants should explore various suitable preprocessing methods as well as different machine learning algorithms to build a robust model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e68f6e-1679-467f-803c-e819d654bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.3, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "def train_model(X_train_scaled, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_scaled, y_true, dataset_name=\"Test\"):\n",
    "    y_pred = model.predict(X_scaled)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"\\n{dataset_name} Evaluation:\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    return y_pred, r2, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cec372-283e-404a-a989-714969c53b0d",
   "metadata": {},
   "source": [
    "<div class=\"section\">\n",
    "  <h2>Model Workflow (Pipeline)</h2>\n",
    "  <p align=\"justify\">\n",
    "    The complete model development process follows a structured pipeline to ensure consistency, reproducibility, and clarity. \n",
    "    Each stage in the workflow is modularized into independent functions, which can be reused for different water quality parameters. \n",
    "    This modular approach helps streamline the process and makes the workflow easily adaptable to new datasets or parameters in the future.\n",
    "  </p>\n",
    "\n",
    "  <p align=\"justify\">\n",
    "    The pipeline automates the sequence of steps — from data preparation to evaluation — for each target parameter. \n",
    "    The same set of predictor variables is used, while the response variable changes for each of the three targets: \n",
    "    <i>Total Alkalinity (TA)</i>, <i>Electrical Conductance (EC)</i>, and <i>Dissolved Reactive Phosphorus (DRP)</i>. \n",
    "    By maintaining a consistent framework, comparisons across models remain fair and interpretable.\n",
    "  </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40808f99-8014-4746-91ae-5b64c61e04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(X, y, param_name=\"Parameter\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Model for {param_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    # Scale\n",
    "    X_train_scaled, X_test_scaled, scaler = scale_data(X_train, X_test)\n",
    "    \n",
    "    # Train\n",
    "    model = train_model(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate (in-sample)\n",
    "    y_train_pred, r2_train, rmse_train = evaluate_model(model, X_train_scaled, y_train, \"Train\")\n",
    "    \n",
    "    # Evaluate (out-sample)\n",
    "    y_test_pred, r2_test, rmse_test = evaluate_model(model, X_test_scaled, y_test, \"Test\")\n",
    "    \n",
    "    # Return summary\n",
    "    results = {\n",
    "        \"Parameter\": param_name,\n",
    "        \"R2_Train\": r2_train,\n",
    "        \"RMSE_Train\": rmse_train,\n",
    "        \"R2_Test\": r2_test,\n",
    "        \"RMSE_Test\": rmse_test\n",
    "    }\n",
    "    return model, scaler, pd.DataFrame([results])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783a30e-ee66-4c50-a957-b67296e9328c",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation for Each Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f39fd-a577-4eff-9fa5-caa9d7f2fcda",
   "metadata": {},
   "source": [
    "<p align=\"justify\">In this step, we apply the complete modeling pipeline to each of the three selected water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. The input feature set (<code>X</code>) remains the same across all three models, while the target variable (<code>y</code>) changes for each parameter. For every parameter, the <code>run_pipeline()</code> function is executed, which handles data preprocessing, model training, and both in-sample and out-of-sample evaluation. This ensures a consistent workflow and allows for a fair comparison of model performance across different water quality indicators.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d5f62b-585c-45e0-8fa9-73a5fa1248f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Model for Total Alkalinity\n",
      "============================================================\n",
      "\n",
      "Train Evaluation:\n",
      "R²: 0.903\n",
      "RMSE: 23.132\n",
      "\n",
      "Test Evaluation:\n",
      "R²: 0.546\n",
      "RMSE: 50.870\n",
      "\n",
      "============================================================\n",
      "Training Model for Electrical Conductance\n",
      "============================================================\n",
      "\n",
      "Train Evaluation:\n",
      "R²: 0.918\n",
      "RMSE: 98.007\n",
      "\n",
      "Test Evaluation:\n",
      "R²: 0.585\n",
      "RMSE: 219.999\n",
      "\n",
      "============================================================\n",
      "Training Model for Dissolved Reactive Phosphorus\n",
      "============================================================\n",
      "\n",
      "Train Evaluation:\n",
      "R²: 0.882\n",
      "RMSE: 17.455\n",
      "\n",
      "Test Evaluation:\n",
      "R²: 0.529\n",
      "RMSE: 35.182\n"
     ]
    }
   ],
   "source": [
    "X = wq_data.drop(columns=['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus'])\n",
    "\n",
    "y_TA = wq_data['Total Alkalinity']\n",
    "y_EC = wq_data['Electrical Conductance']\n",
    "y_DRP = wq_data['Dissolved Reactive Phosphorus']\n",
    "\n",
    "model_TA, scaler_TA, results_TA = run_pipeline(X, y_TA, \"Total Alkalinity\")\n",
    "model_EC, scaler_EC, results_EC = run_pipeline(X, y_EC, \"Electrical Conductance\")\n",
    "model_DRP, scaler_DRP, results_DRP = run_pipeline(X, y_DRP, \"Dissolved Reactive Phosphorus\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a854c-a8af-411e-b5af-e78d064d80a1",
   "metadata": {},
   "source": [
    "### Model Performance Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4c7a8-c192-469f-8a18-972f4900da2b",
   "metadata": {},
   "source": [
    "<p align=\"justify\">After training and evaluating the models for each water quality parameter, the individual performance metrics are combined into a single summary table. This table consolidates the R² and RMSE values for both in-sample and out-of-sample evaluations, enabling an easy comparison of model performance across Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. Such a summary provides a quick overview of how well each model captures the variability in the respective parameter and highlights any differences in predictive accuracy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f3a047-a05c-4369-8a84-5b287f1ff272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>RMSE_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Alkalinity</td>\n",
       "      <td>0.903199</td>\n",
       "      <td>23.132468</td>\n",
       "      <td>0.545661</td>\n",
       "      <td>50.870362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electrical Conductance</td>\n",
       "      <td>0.917884</td>\n",
       "      <td>98.007101</td>\n",
       "      <td>0.585458</td>\n",
       "      <td>219.998675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dissolved Reactive Phosphorus</td>\n",
       "      <td>0.882169</td>\n",
       "      <td>17.454757</td>\n",
       "      <td>0.529145</td>\n",
       "      <td>35.181776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Parameter  R2_Train  RMSE_Train   R2_Test   RMSE_Test\n",
       "0               Total Alkalinity  0.903199   23.132468  0.545661   50.870362\n",
       "1         Electrical Conductance  0.917884   98.007101  0.585458  219.998675\n",
       "2  Dissolved Reactive Phosphorus  0.882169   17.454757  0.529145   35.181776"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\n",
    "results_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624dfbd-49ed-4fc3-9904-46eed6796fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5277b08-d7bc-4b7c-91bf-26fa19795f56",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c5dde-8a39-4e16-bdd9-93ce024850d2",
   "metadata": {},
   "source": [
    "<p align=\"justify\">Once you are satisfied with your model’s performance, you can proceed to make predictions for unseen data. To do this, use your trained model to estimate the concentrations of the target water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus — for a set of test locations provided in the \"Submission_template.csv\" file. The predicted results can then be uploaded to the challenge platform for evaluation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c561f152-2058-4c0a-b458-835892607989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -32.043333  27.822778  01-09-2014               NaN                     NaN   \n",
       "1 -33.329167  26.077500  16-09-2015               NaN                     NaN   \n",
       "2 -32.991639  27.640028  07-05-2015               NaN                     NaN   \n",
       "3 -34.096389  24.439167  07-02-2012               NaN                     NaN   \n",
       "4 -32.000556  28.581667  01-10-2014               NaN                     NaN   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the coordinates for the submission\n",
    "test_file = pd.read_csv('submission_template.csv')\n",
    "test_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feacaed-272c-4812-8c14-d2bd6a8d48f1",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "Similarly, participants can use the <b>Landsat</b> and <b>TerraClimate</b> data extraction demonstration notebooks to produce feature CSVs for their <b>validation</b> data. For convenience, we have already computed and saved example validation outputs as <code>landsat_features_val_V3.csv</code> and <code>Terraclimate_val_df_v3.csv</code>. Participants should save their own extracted files in the same format and column schema; doing so will allow this benchmark notebook to load the validation features directly and run smoothly.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c79a123-b5d1-482a-b82e-2b1ef87773e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>nir</th>\n",
       "      <th>green</th>\n",
       "      <th>swir16</th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>15229.0</td>\n",
       "      <td>12868.0</td>\n",
       "      <td>14797.0</td>\n",
       "      <td>12421.0</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.069727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>16221.0</td>\n",
       "      <td>9304.5</td>\n",
       "      <td>12536.5</td>\n",
       "      <td>9958.0</td>\n",
       "      <td>0.128123</td>\n",
       "      <td>-0.147979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>11100.5</td>\n",
       "      <td>9455.0</td>\n",
       "      <td>8711.0</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>0.080052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date      nir    green   swir16   swir22  \\\n",
       "0 -32.043333  27.822778  01-09-2014  15229.0  12868.0  14797.0  12421.0   \n",
       "1 -33.329167  26.077500  16-09-2015      NaN      NaN      NaN      NaN   \n",
       "2 -32.991639  27.640028  07-05-2015  16221.0   9304.5  12536.5   9958.0   \n",
       "3 -34.096389  24.439167  07-02-2012      NaN      NaN      NaN      NaN   \n",
       "4 -32.000556  28.581667  01-10-2014   9125.0  11100.5   9455.0   8711.0   \n",
       "\n",
       "       NDMI     MNDWI  \n",
       "0  0.014388 -0.069727  \n",
       "1       NaN       NaN  \n",
       "2  0.128123 -0.147979  \n",
       "3       NaN       NaN  \n",
       "4 -0.017761  0.080052  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat_val_features = pd.read_csv('landsat_features_validation.csv')\n",
    "landsat_val_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5c5ce3-6665-4ba0-8f8a-99d34be8ddce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>161.90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>177.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>158.40001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>130.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>152.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date        pet\n",
       "0 -32.043333  27.822778  01-09-2014  161.90001\n",
       "1 -33.329167  26.077500  16-09-2015  177.60000\n",
       "2 -32.991639  27.640028  07-05-2015  158.40001\n",
       "3 -34.096389  24.439167  07-02-2012  130.00000\n",
       "4 -32.000556  28.581667  01-10-2014  152.50000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Terraclimate_val_df = pd.read_csv('terraclimate_features_validation.csv')\n",
    "Terraclimate_val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dabb48-7f82-4acf-b509-21cc15a5a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consolidate all the extracted bands and features in a single dataframe\n",
    "val_data = pd.DataFrame({\n",
    "    'Longitude': landsat_val_features['Longitude'].values,\n",
    "    'Latitude': landsat_val_features['Latitude'].values,\n",
    "    'Sample Date': landsat_val_features['Sample Date'].values,\n",
    "    'nir': landsat_val_features['nir'].values,\n",
    "    'green': landsat_val_features['green'].values,\n",
    "    'swir16': landsat_val_features['swir16'].values,\n",
    "    'swir22': landsat_val_features['swir22'].values,\n",
    "    'NDMI': landsat_val_features['NDMI'].values,\n",
    "    'MNDWI': landsat_val_features['MNDWI'].values,\n",
    "    'pet': Terraclimate_val_df['pet'].values,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c41d268-0657-490b-94f3-8ffeb67c2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values\n",
    "val_data = val_data.fillna(val_data.median(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126bf77-fb54-4609-a09c-8e36b496d108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swir22</th>\n",
       "      <th>NDMI</th>\n",
       "      <th>MNDWI</th>\n",
       "      <th>pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12421.0</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>-0.069727</td>\n",
       "      <td>161.90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9973.0</td>\n",
       "      <td>0.081427</td>\n",
       "      <td>-0.130571</td>\n",
       "      <td>177.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9958.0</td>\n",
       "      <td>0.128123</td>\n",
       "      <td>-0.147979</td>\n",
       "      <td>158.40001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9973.0</td>\n",
       "      <td>0.081427</td>\n",
       "      <td>-0.130571</td>\n",
       "      <td>130.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8711.0</td>\n",
       "      <td>-0.017761</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>152.50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    swir22      NDMI     MNDWI        pet\n",
       "0  12421.0  0.014388 -0.069727  161.90001\n",
       "1   9973.0  0.081427 -0.130571  177.60000\n",
       "2   9958.0  0.128123 -0.147979  158.40001\n",
       "3   9973.0  0.081427 -0.130571  130.00000\n",
       "4   8711.0 -0.017761  0.080052  152.50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting specific columns (swir22, NDMI, MNDWI, pet) from the validation dataset\n",
    "submission_val_data=val_data.loc[:,['swir22','NDMI','MNDWI','pet']]\n",
    "submission_val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7b033c7-3d5f-4179-b8f8-182f8caad0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87b59132-ff14-421e-b37b-472a0adcd9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Predicting for Total Alkalinity ---\n",
    "X_sub_scaled_TA = scaler_TA.transform(submission_val_data)\n",
    "pred_TA_submission = model_TA.predict(X_sub_scaled_TA)\n",
    "\n",
    "# --- Predicting for Electrical Conductance ---\n",
    "X_sub_scaled_EC = scaler_EC.transform(submission_val_data)\n",
    "pred_EC_submission = model_EC.predict(X_sub_scaled_EC)\n",
    "\n",
    "# --- Predicting for Dissolved Reactive Phosphorus ---\n",
    "X_sub_scaled_DRP = scaler_DRP.transform(submission_val_data)\n",
    "pred_DRP_submission = model_DRP.predict(X_sub_scaled_DRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "398e375c-60cc-4fa5-a697-ae12fdab300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'Longitude': test_file['Longitude'].values,\n",
    "    'Latitude': test_file['Latitude'].values,\n",
    "    'Sample Date': test_file['Sample Date'].values,\n",
    "    'Total Alkalinity': pred_TA_submission,\n",
    "    'Electrical Conductance': pred_EC_submission,\n",
    "    'Dissolved Reactive Phosphorus': pred_DRP_submission\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46e1c4fa-e49f-40cf-ac10-729b82c4b37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.822778</td>\n",
       "      <td>-32.043333</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>114.833126</td>\n",
       "      <td>314.267271</td>\n",
       "      <td>25.235333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.077500</td>\n",
       "      <td>-33.329167</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>156.957291</td>\n",
       "      <td>648.500033</td>\n",
       "      <td>60.455833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.640028</td>\n",
       "      <td>-32.991639</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>62.877980</td>\n",
       "      <td>724.577283</td>\n",
       "      <td>29.445333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.439167</td>\n",
       "      <td>-34.096389</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>72.334447</td>\n",
       "      <td>234.950986</td>\n",
       "      <td>13.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.581667</td>\n",
       "      <td>-32.000556</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>109.078753</td>\n",
       "      <td>304.010200</td>\n",
       "      <td>30.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude   Latitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0  27.822778 -32.043333  01-09-2014        114.833126              314.267271   \n",
       "1  26.077500 -33.329167  16-09-2015        156.957291              648.500033   \n",
       "2  27.640028 -32.991639  07-05-2015         62.877980              724.577283   \n",
       "3  24.439167 -34.096389  07-02-2012         72.334447              234.950986   \n",
       "4  28.581667 -32.000556  01-10-2014        109.078753              304.010200   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                      25.235333  \n",
       "1                      60.455833  \n",
       "2                      29.445333  \n",
       "3                      13.726667  \n",
       "4                      30.210000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the sample submission dataframe\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3a8c41-dba2-43e4-b84c-a50a096980e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dumping the predictions into a csv file.\n",
    "submission_df.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7af545-7a55-4b59-9edc-bc43f47bffd5",
   "metadata": {},
   "source": [
    "### Upload submission file on platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09295666-21e5-4609-b7b7-a44fa113aad7",
   "metadata": {},
   "source": [
    "Upload the submission.csv on the <a href =\"https://challenge.ey.com\">platform</a> to get score generated on scoreboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab09ba-3b69-4a2a-a56e-2dbf084e0c56",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<div align =\"justify\">Now that you have learned a basic approach to model training, it’s time to try your own approach! Feel free to modify any of the functions presented in this notebook. We look forward to seeing your version of the model and the results. Best of luck with the challenge!</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
